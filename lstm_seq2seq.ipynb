{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9AjsoJbSIJm"
      },
      "source": [
        "# Character-level recurrent sequence-to-sequence model\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2017/09/29<br>\n",
        "**Last modified:** 2020/04/26<br>\n",
        "**Description:** Character-level recurrent sequence-to-sequence model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLQW-YkLSIJq"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example demonstrates how to implement a basic character-level\n",
        "recurrent sequence-to-sequence model. We apply it to translating\n",
        "short English sentences into short French sentences,\n",
        "character-by-character. Note that it is fairly unusual to\n",
        "do character-level machine translation, as word-level\n",
        "models are more common in this domain.\n",
        "\n",
        "**Summary of the algorithm**\n",
        "\n",
        "- We start with input sequences from a domain (e.g. English sentences)\n",
        "    and corresponding target sequences from another domain\n",
        "    (e.g. French sentences).\n",
        "- An encoder LSTM turns input sequences to 2 state vectors\n",
        "    (we keep the last LSTM state and discard the outputs).\n",
        "- A decoder LSTM is trained to turn the target sequences into\n",
        "    the same sequence but offset by one timestep in the future,\n",
        "    a training process called \"teacher forcing\" in this context.\n",
        "    It uses as initial state the state vectors from the encoder.\n",
        "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
        "    given `targets[...t]`, conditioned on the input sequence.\n",
        "- In inference mode, when we want to decode unknown input sequences, we:\n",
        "    - Encode the input sequence into state vectors\n",
        "    - Start with a target sequence of size 1\n",
        "        (just the start-of-sequence character)\n",
        "    - Feed the state vectors and 1-char target sequence\n",
        "        to the decoder to produce predictions for the next character\n",
        "    - Sample the next character using these predictions\n",
        "        (we simply use argmax).\n",
        "    - Append the sampled character to the target sequence\n",
        "    - Repeat until we generate the end-of-sequence character or we\n",
        "        hit the character limit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC3KUPeza7mn",
        "outputId": "f216a147-093a-4a64-de29-e6a34e1f6fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aicrowd-cli in /usr/local/lib/python3.7/dist-packages (0.1.15)\n",
            "Requirement already satisfied: requests<3,>=2.25.1 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (2.27.1)\n",
            "Requirement already satisfied: pyzmq==22.1.0 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (22.1.0)\n",
            "Requirement already satisfied: semver<3,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (2.13.0)\n",
            "Requirement already satisfied: click<8,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (7.1.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.56.0 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (4.64.0)\n",
            "Requirement already satisfied: GitPython==3.1.18 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (3.1.18)\n",
            "Requirement already satisfied: python-slugify<6,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (5.0.2)\n",
            "Requirement already satisfied: requests-toolbelt<1,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (0.9.1)\n",
            "Requirement already satisfied: toml<1,>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (0.10.2)\n",
            "Requirement already satisfied: rich<11,>=10.0.0 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (10.16.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython==3.1.18->aicrowd-cli) (4.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython==3.1.18->aicrowd-cli) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython==3.1.18->aicrowd-cli) (5.0.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify<6,>=5.0.0->aicrowd-cli) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2.10)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (2.6.1)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (0.9.1)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (0.4.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install aicrowd-cli\n",
        "%load_ext aicrowd.magic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9oUz9npa-hW",
        "outputId": "34f2261a-6c1f-4dfc-8f96-339e8575cde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please login here: \u001b[34m\u001b[1m\u001b[4mhttps://api.aicrowd.com/auth/p5zGic61w3C8FAMqlWzYHqf57ZhEwiqsx8922wIJR6M\u001b[0m\n",
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mGitlab access token valid\u001b[0m\n",
            "\u001b[32mSaved details successfully!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%aicrowd login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpAsEUKMSIJr"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrvM2jU6SIJs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9n2D0nIbNzH",
        "outputId": "1cd6b138-a8c6-4a59-d489-949df946bfef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pywer in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from pywer) (0.5.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pywer\n",
        "import pywer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXOGf0m1SIJt"
      },
      "source": [
        "## Download the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G_tmJK8SIJu"
      },
      "outputs": [],
      "source": [
        "# !!curl -O http://www.manythings.org/anki/fra-eng.zip\n",
        "# !!unzip fra-eng.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "1178144ea0454fd2b55a83ea185a7f47",
            "fd5443463eb0420e92ba13900eb70baa",
            "ee7917315b9a4387ae16e69d79aa677f",
            "2dcc5bd8c93949e0adf684dc8ae543e3",
            "f273f507bec74316b72246a77b21c74c",
            "9a3d73af91424aa49bb6378b6d30de7f",
            "880917de59614bbbb5251c6151397a20",
            "e5f0f48edce243379df5a1308612d1a0",
            "be4bd1fd2c0e46fd8119273e2a3d965e",
            "603eaeb4996e4a5e9d2b1584a8539da3",
            "986e33e5a31e46c28ce149efdd0ea31a",
            "c1986e8da3ea486797a0b18ac364c5a1",
            "962aafdf60d7424c824fa03219d97fd9",
            "5ce2a00a18bf43349aa327924bd85208",
            "5f5227031fdc4ed9b929913e9ecb39f3",
            "f42168c9d4534e73a681373b330dea85",
            "f7cbfbaac24d477ab16a0e3792deb7f7",
            "b639396a16b140399931daf33570b139",
            "1c4790797b264b71a2e483c968c80126",
            "7b487fa018c74669aeaeaae4b65cb79f",
            "a64f38a1cd524297826e514effc8e21e",
            "fde364e916f64dccb74f164063ca4bfc"
          ]
        },
        "id": "HqWD3vF9bEVf",
        "outputId": "40bfdbf6-f2e3-43b6-8758-9fe58784bd3c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.csv:   0%|          | 0.00/45.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1178144ea0454fd2b55a83ea185a7f47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.csv:   0%|          | 0.00/395k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1986e8da3ea486797a0b18ac364c5a1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!rm -rf data\n",
        "!mkdir data\n",
        "%aicrowd ds dl -c htrec-2022 -o data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YahHdKUibXBu"
      },
      "outputs": [],
      "source": [
        "# with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "#     lines = f.read().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HmN8f5KbYDX"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"data/train.csv\")\n",
        "test_df = pd.read_csv(\"data/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clear_vowels(df,cols):\n",
        "  for i in cols:\n",
        "    df[i] = df[i].apply(lambda x: re.sub(r'ά|α|ὰ|ά|ᾄ|ᾅ|ὰ|ά|ᾳ|ᾴ|ᾶ|ᾷ|ἀ|ἁ|ἂ|ἃ|ἄ|ἅ|ἇ|Ἀ|Ἁ|Ἄ|Ἅ|Α','α',x.lower()))\n",
        "    df[i] = df[i].apply(lambda x: re.sub(r'έ|ε|ὲ|έ|ἐ|ἑ|ἔ|ἕ|Ἐ|Ἑ|Ἔ|Ἕ|Ε','ε',x))\n",
        "    df[i] = df[i].apply(lambda x: re.sub(r'ή|ή|η|ᾑ|ᾔ|ᾗ|ὴ|ή|ῃ|ῄ|ῆ|ῇ|ἠ|ἡ|ἢ|ἣ|ἤ|ἥ|ἦ|ἧ|Ἡ|Η','η',x))\n",
        "    df[i] = df[i].apply(lambda x: re.sub(r'ΐ|ί|ι|ϊ|ὶ|ί|ῒ|ῖ|ἰ|ἱ|ἳ|ἴ|ἵ|ἶ|ἷ|Ἰ|Ἱ|Ἴ','ι',x))\n",
        "    df[i] = df[i].apply(lambda x: re.sub( r'ο|ό|ὸ|ό|ὀ|ὁ|ὃ|ὄ|ὅ|Ὁ|Ὃ|Ὅ|Ο','ο',x))\n",
        "    df[i] = df[i].apply(lambda x: re.sub(r'ῤ|ῥ','ρ',x))\n",
        "    df[i] = df[i].apply(lambda x: re.sub(r'ῦ|υ|ύ|ὺ|ύ|ὐ|ὑ|ὓ|ὔ|ὕ|ὖ|ὗ|Ὑ','υ',x))\n",
        "    df[i] = df[i].apply(lambda x: re.sub(r'ω|ᾠ|ᾤ|ᾦ|ᾧ|ὼ|ώ|ὠ|ὡ|ὢ|ὣ|ὤ|ὥ|ὦ|ὧ|Ὠ|Ὡ|Ὥ|Ὦ|ῳ|ῴ|ῶ|ῷ|ώ|Ω','ω',x))\n",
        "    df[i] = df[i].apply(lambda x: re.sub(r'\\W',' ',x)) #remove non words characters\n",
        "    df[i] = df[i].apply(lambda x: re.sub(r'\\s\\s+',' ',x)) #collapse multiple whitespaces\n",
        "  return(df)\n",
        "\n",
        "clear_vowels(train_df,[\"HUMAN_TRANSCRIPTION\",\"SYSTEM_TRANSCRIPTION\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "4ktnrma5S4AX",
        "outputId": "3c9f1af6-5d02-4090-dab3-6da37757764c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    HUMAN_TRANSCRIPTION  \\\n",
              "0         εγγινομενα παθη μη σβεννυντες αλλα τη εκλυσει   \n",
              "1     του βιου του καθ εαυτους πολλα γινεσθαι συγχωρουν   \n",
              "2           τες εμπυριζουσι τον αμπελωνα αλλα και ο δια   \n",
              "3         της ηδειας πλεονεξιας πολλους εις την των αλλ   \n",
              "4                 οτριων επιθυμιαν προκαλουμενος εμπυρι   \n",
              "...                                                 ...   \n",
              "1870    σριαν του των ανων γενους γεγονε ανος και τι λε   \n",
              "1871         γω την ημετεραν υπεδυ σαρκα και τ αλλα παν   \n",
              "1872      τα ανινα υπεμεινεν οπου γε και τον στρον κατε   \n",
              "1873            δεξατο ινα ημας τους υπο αμαρτιων προδε   \n",
              "1874            δομενους της καταρας ελευθερωση και βοα   \n",
              "\n",
              "                                 SYSTEM_TRANSCRIPTION  CENTURY  \\\n",
              "0            εγγενομεναπαδημησμεννωτες αλλατηε κλησει       11   \n",
              "1     του β ου του καλεαυτους πολλαγινεσθαι συγχωρ ον       11   \n",
              "2              τες εμπυριζου σιμαμπελωνα αλλακαι οδξα       11   \n",
              "3        της εδιας πλσον εξιας πολλους εις την των αλ       11   \n",
              "4              λοτρλων επιθυμιαν προκαλουμενος εμπυρι       11   \n",
              "...                                               ...      ...   \n",
              "1870         σριαν τουτων ανων γενθυγεγονενανος οτιμε       10   \n",
              "1871            γω την η μετεραν υπεθσαρκα ειταλλαπαν       10   \n",
              "1872          τα ανινα υπεμειμεν οπουγεκαι ετριν κατε       10   \n",
              "1873           δεξατο ινα ημας τους υποαμαρτιων προδε       10   \n",
              "1874              δομενους της καταρας ελευθερωσηψβοα       10   \n",
              "\n",
              "                                             IMAGE_PATH  TEXT_LINE_NUM  \n",
              "0     1 Bodleian-Library-MS-Barocci-102_00157_fol-75...              1  \n",
              "1     1 Bodleian-Library-MS-Barocci-102_00157_fol-75...              2  \n",
              "2     1 Bodleian-Library-MS-Barocci-102_00157_fol-75...              3  \n",
              "3     1 Bodleian-Library-MS-Barocci-102_00157_fol-75...              4  \n",
              "4     1 Bodleian-Library-MS-Barocci-102_00157_fol-75...              5  \n",
              "...                                                 ...            ...  \n",
              "1870  100 Bodleian-Library-MS-Barocci-184_00040_fol-...             25  \n",
              "1871  100 Bodleian-Library-MS-Barocci-184_00040_fol-...             26  \n",
              "1872  100 Bodleian-Library-MS-Barocci-184_00040_fol-...             27  \n",
              "1873  100 Bodleian-Library-MS-Barocci-184_00040_fol-...             28  \n",
              "1874  100 Bodleian-Library-MS-Barocci-184_00040_fol-...             29  \n",
              "\n",
              "[1875 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01b51088-4bd3-4e5c-942f-1b2d051b4156\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HUMAN_TRANSCRIPTION</th>\n",
              "      <th>SYSTEM_TRANSCRIPTION</th>\n",
              "      <th>CENTURY</th>\n",
              "      <th>IMAGE_PATH</th>\n",
              "      <th>TEXT_LINE_NUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>εγγινομενα παθη μη σβεννυντες αλλα τη εκλυσει</td>\n",
              "      <td>εγγενομεναπαδημησμεννωτες αλλατηε κλησει</td>\n",
              "      <td>11</td>\n",
              "      <td>1 Bodleian-Library-MS-Barocci-102_00157_fol-75...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>του βιου του καθ εαυτους πολλα γινεσθαι συγχωρουν</td>\n",
              "      <td>του β ου του καλεαυτους πολλαγινεσθαι συγχωρ ον</td>\n",
              "      <td>11</td>\n",
              "      <td>1 Bodleian-Library-MS-Barocci-102_00157_fol-75...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>τες εμπυριζουσι τον αμπελωνα αλλα και ο δια</td>\n",
              "      <td>τες εμπυριζου σιμαμπελωνα αλλακαι οδξα</td>\n",
              "      <td>11</td>\n",
              "      <td>1 Bodleian-Library-MS-Barocci-102_00157_fol-75...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>της ηδειας πλεονεξιας πολλους εις την των αλλ</td>\n",
              "      <td>της εδιας πλσον εξιας πολλους εις την των αλ</td>\n",
              "      <td>11</td>\n",
              "      <td>1 Bodleian-Library-MS-Barocci-102_00157_fol-75...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>οτριων επιθυμιαν προκαλουμενος εμπυρι</td>\n",
              "      <td>λοτρλων επιθυμιαν προκαλουμενος εμπυρι</td>\n",
              "      <td>11</td>\n",
              "      <td>1 Bodleian-Library-MS-Barocci-102_00157_fol-75...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1870</th>\n",
              "      <td>σριαν του των ανων γενους γεγονε ανος και τι λε</td>\n",
              "      <td>σριαν τουτων ανων γενθυγεγονενανος οτιμε</td>\n",
              "      <td>10</td>\n",
              "      <td>100 Bodleian-Library-MS-Barocci-184_00040_fol-...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1871</th>\n",
              "      <td>γω την ημετεραν υπεδυ σαρκα και τ αλλα παν</td>\n",
              "      <td>γω την η μετεραν υπεθσαρκα ειταλλαπαν</td>\n",
              "      <td>10</td>\n",
              "      <td>100 Bodleian-Library-MS-Barocci-184_00040_fol-...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1872</th>\n",
              "      <td>τα ανινα υπεμεινεν οπου γε και τον στρον κατε</td>\n",
              "      <td>τα ανινα υπεμειμεν οπουγεκαι ετριν κατε</td>\n",
              "      <td>10</td>\n",
              "      <td>100 Bodleian-Library-MS-Barocci-184_00040_fol-...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1873</th>\n",
              "      <td>δεξατο ινα ημας τους υπο αμαρτιων προδε</td>\n",
              "      <td>δεξατο ινα ημας τους υποαμαρτιων προδε</td>\n",
              "      <td>10</td>\n",
              "      <td>100 Bodleian-Library-MS-Barocci-184_00040_fol-...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1874</th>\n",
              "      <td>δομενους της καταρας ελευθερωση και βοα</td>\n",
              "      <td>δομενους της καταρας ελευθερωσηψβοα</td>\n",
              "      <td>10</td>\n",
              "      <td>100 Bodleian-Library-MS-Barocci-184_00040_fol-...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1875 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01b51088-4bd3-4e5c-942f-1b2d051b4156')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01b51088-4bd3-4e5c-942f-1b2d051b4156 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01b51088-4bd3-4e5c-942f-1b2d051b4156');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBnx0C9HSIJv"
      },
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgQ0vdfYSIJv"
      },
      "outputs": [],
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 1000  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "\n",
        "# # Path to the data txt file on disk.\n",
        "# data_path = \"fra.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp8cEhqJSIJw"
      },
      "source": [
        "## Prepare the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pQQN8D6bwYX",
        "outputId": "661e9de5-6595-4596-dd64-96b1bfb70afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ],
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "train_df[\"Proc_human\"] = train_df['HUMAN_TRANSCRIPTION'].copy()\n",
        "\n",
        "for i in range(len(train_df[\"Proc_human\"])):\n",
        "\n",
        "    train_df[\"Proc_human\"][i] = \"\\t\" + train_df[\"Proc_human\"][i] + \"\\n\"\n",
        "\n",
        "    input_text = train_df[\"SYSTEM_TRANSCRIPTION\"][i]\n",
        "    target_text = train_df[\"Proc_human\"][i]\n",
        "\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec0DUvP4auD4"
      },
      "outputs": [],
      "source": [
        "# # Vectorize the data.\n",
        "# input_texts = []\n",
        "# target_texts = []\n",
        "# input_characters = set()\n",
        "# target_characters = set()\n",
        "\n",
        "# for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "#     input_text, target_text, _ = line.split(\"\\t\")\n",
        "#     # We use \"tab\" as the \"start sequence\" character\n",
        "#     # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "#     target_text = \"\\t\" + target_text + \"\\n\"\n",
        "#     input_texts.append(input_text)\n",
        "#     target_texts.append(target_text)\n",
        "#     for char in input_text:\n",
        "#         if char not in input_characters:\n",
        "#             input_characters.add(char)\n",
        "#     for char in target_text:\n",
        "#         if char not in target_characters:\n",
        "#             target_characters.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR3Ls8oEcjiY",
        "outputId": "1c993b56-00a9-4e4e-89af-3ab2e112c7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 1875\n",
            "Number of unique input tokens: 26\n",
            "Number of unique output tokens: 28\n",
            "Max sequence length for inputs: 83\n",
            "Max sequence length for outputs: 87\n"
          ]
        }
      ],
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQqxYpWaSIJx"
      },
      "outputs": [],
      "source": [
        "# input_characters = sorted(list(input_characters))\n",
        "# target_characters = sorted(list(target_characters))\n",
        "# num_encoder_tokens = len(input_characters)\n",
        "# num_decoder_tokens = len(target_characters)\n",
        "# max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "# max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "# print(\"Number of samples:\", len(input_texts))\n",
        "# print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "# print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "# print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "# print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGbqRNc-axC_"
      },
      "outputs": [],
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVv0OEhvSIJy"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3WSuBCLSIJy"
      },
      "outputs": [],
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZipH9oJSIJz"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gG4h9lnZ1B3",
        "outputId": "ef113b38-2804-4636-f5e4-44824a61564b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1875, 83, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "encoder_input_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb0Qbd4IVlmg",
        "outputId": "ba17a05f-92c3-4b87-af37-ca35a47e25b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 1., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "encoder_input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ng4io-MCSIJ0",
        "outputId": "9bb80df9-ee41-40b4-e5f1-4f90497f2ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "24/24 [==============================] - 9s 93ms/step - loss: 1.8267 - accuracy: 0.5876 - val_loss: 1.7614 - val_accuracy: 0.5548\n",
            "Epoch 2/1000\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 1.5484 - accuracy: 0.6142 - val_loss: 1.6534 - val_accuracy: 0.5550\n",
            "Epoch 3/1000\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 1.4051 - accuracy: 0.6176 - val_loss: 1.5800 - val_accuracy: 0.5612\n",
            "Epoch 4/1000\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 1.3504 - accuracy: 0.6207 - val_loss: 1.5157 - val_accuracy: 0.5624\n",
            "Epoch 5/1000\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 1.4258 - accuracy: 0.6195 - val_loss: 1.5100 - val_accuracy: 0.5645\n",
            "Epoch 6/1000\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.2921 - accuracy: 0.6262 - val_loss: 1.4389 - val_accuracy: 0.5837\n",
            "Epoch 7/1000\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 1.2525 - accuracy: 0.6383 - val_loss: 1.4133 - val_accuracy: 0.6059\n",
            "Epoch 8/1000\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 1.1987 - accuracy: 0.6507 - val_loss: 1.3152 - val_accuracy: 0.6073\n",
            "Epoch 9/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 1.1612 - accuracy: 0.6607 - val_loss: 1.2773 - val_accuracy: 0.6212\n",
            "Epoch 10/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 1.1162 - accuracy: 0.6680 - val_loss: 1.2450 - val_accuracy: 0.6238\n",
            "Epoch 11/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 1.0908 - accuracy: 0.6732 - val_loss: 1.2213 - val_accuracy: 0.6287\n",
            "Epoch 12/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 1.0687 - accuracy: 0.6757 - val_loss: 1.2045 - val_accuracy: 0.6387\n",
            "Epoch 13/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 1.0984 - accuracy: 0.6772 - val_loss: 1.1787 - val_accuracy: 0.6368\n",
            "Epoch 14/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 1.0375 - accuracy: 0.6808 - val_loss: 1.1643 - val_accuracy: 0.6381\n",
            "Epoch 15/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 1.0298 - accuracy: 0.6814 - val_loss: 1.1564 - val_accuracy: 0.6406\n",
            "Epoch 16/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 1.0211 - accuracy: 0.6824 - val_loss: 1.1464 - val_accuracy: 0.6442\n",
            "Epoch 17/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.0117 - accuracy: 0.6843 - val_loss: 1.1375 - val_accuracy: 0.6457\n",
            "Epoch 18/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.0049 - accuracy: 0.6858 - val_loss: 1.1353 - val_accuracy: 0.6469\n",
            "Epoch 19/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9962 - accuracy: 0.6884 - val_loss: 1.1263 - val_accuracy: 0.6444\n",
            "Epoch 20/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9908 - accuracy: 0.6896 - val_loss: 1.1274 - val_accuracy: 0.6460\n",
            "Epoch 21/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.9846 - accuracy: 0.6916 - val_loss: 1.1234 - val_accuracy: 0.6480\n",
            "Epoch 22/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9784 - accuracy: 0.6928 - val_loss: 1.1182 - val_accuracy: 0.6513\n",
            "Epoch 23/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.9724 - accuracy: 0.6940 - val_loss: 1.1063 - val_accuracy: 0.6556\n",
            "Epoch 24/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.9666 - accuracy: 0.6962 - val_loss: 1.1085 - val_accuracy: 0.6510\n",
            "Epoch 25/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.9609 - accuracy: 0.6980 - val_loss: 1.1005 - val_accuracy: 0.6574\n",
            "Epoch 26/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9557 - accuracy: 0.6995 - val_loss: 1.0936 - val_accuracy: 0.6568\n",
            "Epoch 27/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.9489 - accuracy: 0.7024 - val_loss: 1.0889 - val_accuracy: 0.6576\n",
            "Epoch 28/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.9429 - accuracy: 0.7039 - val_loss: 1.0869 - val_accuracy: 0.6603\n",
            "Epoch 29/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9377 - accuracy: 0.7050 - val_loss: 1.0874 - val_accuracy: 0.6584\n",
            "Epoch 30/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.9309 - accuracy: 0.7071 - val_loss: 1.0786 - val_accuracy: 0.6614\n",
            "Epoch 31/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9247 - accuracy: 0.7090 - val_loss: 1.0899 - val_accuracy: 0.6591\n",
            "Epoch 32/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.9194 - accuracy: 0.7102 - val_loss: 1.0808 - val_accuracy: 0.6620\n",
            "Epoch 33/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.9131 - accuracy: 0.7126 - val_loss: 1.0763 - val_accuracy: 0.6630\n",
            "Epoch 34/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.9071 - accuracy: 0.7145 - val_loss: 1.0690 - val_accuracy: 0.6632\n",
            "Epoch 35/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9005 - accuracy: 0.7167 - val_loss: 1.0692 - val_accuracy: 0.6652\n",
            "Epoch 36/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.8944 - accuracy: 0.7178 - val_loss: 1.0624 - val_accuracy: 0.6659\n",
            "Epoch 37/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.8883 - accuracy: 0.7201 - val_loss: 1.0714 - val_accuracy: 0.6612\n",
            "Epoch 38/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.8811 - accuracy: 0.7218 - val_loss: 1.0647 - val_accuracy: 0.6648\n",
            "Epoch 39/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.8743 - accuracy: 0.7241 - val_loss: 1.0650 - val_accuracy: 0.6650\n",
            "Epoch 40/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.8684 - accuracy: 0.7266 - val_loss: 1.0678 - val_accuracy: 0.6637\n",
            "Epoch 41/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.8612 - accuracy: 0.7284 - val_loss: 1.0652 - val_accuracy: 0.6647\n",
            "Epoch 42/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.8554 - accuracy: 0.7305 - val_loss: 1.0691 - val_accuracy: 0.6635\n",
            "Epoch 43/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.8466 - accuracy: 0.7332 - val_loss: 1.0782 - val_accuracy: 0.6606\n",
            "Epoch 44/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.8410 - accuracy: 0.7344 - val_loss: 1.0678 - val_accuracy: 0.6661\n",
            "Epoch 45/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.8323 - accuracy: 0.7368 - val_loss: 1.0740 - val_accuracy: 0.6629\n",
            "Epoch 46/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.8268 - accuracy: 0.7392 - val_loss: 1.0753 - val_accuracy: 0.6638\n",
            "Epoch 47/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.8185 - accuracy: 0.7421 - val_loss: 1.0684 - val_accuracy: 0.6645\n",
            "Epoch 48/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.8108 - accuracy: 0.7445 - val_loss: 1.0775 - val_accuracy: 0.6646\n",
            "Epoch 49/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.8052 - accuracy: 0.7459 - val_loss: 1.0735 - val_accuracy: 0.6653\n",
            "Epoch 50/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.7957 - accuracy: 0.7491 - val_loss: 1.0795 - val_accuracy: 0.6638\n",
            "Epoch 51/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7894 - accuracy: 0.7518 - val_loss: 1.0862 - val_accuracy: 0.6631\n",
            "Epoch 52/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7809 - accuracy: 0.7544 - val_loss: 1.0960 - val_accuracy: 0.6604\n",
            "Epoch 53/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7723 - accuracy: 0.7571 - val_loss: 1.0933 - val_accuracy: 0.6635\n",
            "Epoch 54/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7662 - accuracy: 0.7593 - val_loss: 1.0924 - val_accuracy: 0.6635\n",
            "Epoch 55/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7580 - accuracy: 0.7616 - val_loss: 1.0986 - val_accuracy: 0.6612\n",
            "Epoch 56/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7497 - accuracy: 0.7648 - val_loss: 1.1015 - val_accuracy: 0.6620\n",
            "Epoch 57/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.7428 - accuracy: 0.7674 - val_loss: 1.1087 - val_accuracy: 0.6601\n",
            "Epoch 58/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7342 - accuracy: 0.7700 - val_loss: 1.1297 - val_accuracy: 0.6558\n",
            "Epoch 59/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7268 - accuracy: 0.7728 - val_loss: 1.1230 - val_accuracy: 0.6592\n",
            "Epoch 60/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7186 - accuracy: 0.7749 - val_loss: 1.1360 - val_accuracy: 0.6565\n",
            "Epoch 61/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7110 - accuracy: 0.7777 - val_loss: 1.1229 - val_accuracy: 0.6593\n",
            "Epoch 62/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7029 - accuracy: 0.7802 - val_loss: 1.1415 - val_accuracy: 0.6565\n",
            "Epoch 63/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6953 - accuracy: 0.7833 - val_loss: 1.1448 - val_accuracy: 0.6577\n",
            "Epoch 64/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6872 - accuracy: 0.7858 - val_loss: 1.1605 - val_accuracy: 0.6541\n",
            "Epoch 65/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6800 - accuracy: 0.7876 - val_loss: 1.1615 - val_accuracy: 0.6540\n",
            "Epoch 66/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.6729 - accuracy: 0.7904 - val_loss: 1.1689 - val_accuracy: 0.6546\n",
            "Epoch 67/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6651 - accuracy: 0.7929 - val_loss: 1.1775 - val_accuracy: 0.6514\n",
            "Epoch 68/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.6588 - accuracy: 0.7957 - val_loss: 1.1841 - val_accuracy: 0.6504\n",
            "Epoch 69/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.6477 - accuracy: 0.7990 - val_loss: 1.2038 - val_accuracy: 0.6477\n",
            "Epoch 70/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.6442 - accuracy: 0.7994 - val_loss: 1.1917 - val_accuracy: 0.6527\n",
            "Epoch 71/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.6366 - accuracy: 0.8022 - val_loss: 1.1905 - val_accuracy: 0.6562\n",
            "Epoch 72/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6295 - accuracy: 0.8053 - val_loss: 1.2063 - val_accuracy: 0.6523\n",
            "Epoch 73/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.6215 - accuracy: 0.8078 - val_loss: 1.2116 - val_accuracy: 0.6520\n",
            "Epoch 74/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6161 - accuracy: 0.8092 - val_loss: 1.2132 - val_accuracy: 0.6507\n",
            "Epoch 75/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.6074 - accuracy: 0.8125 - val_loss: 1.2326 - val_accuracy: 0.6480\n",
            "Epoch 76/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6002 - accuracy: 0.8142 - val_loss: 1.2382 - val_accuracy: 0.6467\n",
            "Epoch 77/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5934 - accuracy: 0.8164 - val_loss: 1.2440 - val_accuracy: 0.6464\n",
            "Epoch 78/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5861 - accuracy: 0.8197 - val_loss: 1.2510 - val_accuracy: 0.6463\n",
            "Epoch 79/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.5808 - accuracy: 0.8205 - val_loss: 1.2535 - val_accuracy: 0.6471\n",
            "Epoch 80/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5726 - accuracy: 0.8238 - val_loss: 1.2732 - val_accuracy: 0.6470\n",
            "Epoch 81/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5656 - accuracy: 0.8267 - val_loss: 1.2998 - val_accuracy: 0.6450\n",
            "Epoch 82/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5601 - accuracy: 0.8282 - val_loss: 1.3010 - val_accuracy: 0.6428\n",
            "Epoch 83/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5522 - accuracy: 0.8318 - val_loss: 1.2878 - val_accuracy: 0.6461\n",
            "Epoch 84/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5468 - accuracy: 0.8326 - val_loss: 1.2872 - val_accuracy: 0.6466\n",
            "Epoch 85/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5399 - accuracy: 0.8351 - val_loss: 1.3187 - val_accuracy: 0.6441\n",
            "Epoch 86/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5405 - accuracy: 0.8350 - val_loss: 1.2929 - val_accuracy: 0.6468\n",
            "Epoch 87/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5214 - accuracy: 0.8420 - val_loss: 1.3336 - val_accuracy: 0.6453\n",
            "Epoch 88/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5227 - accuracy: 0.8413 - val_loss: 1.3412 - val_accuracy: 0.6425\n",
            "Epoch 89/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5163 - accuracy: 0.8434 - val_loss: 1.3304 - val_accuracy: 0.6467\n",
            "Epoch 90/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5105 - accuracy: 0.8446 - val_loss: 1.3484 - val_accuracy: 0.6420\n",
            "Epoch 91/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5057 - accuracy: 0.8472 - val_loss: 1.3530 - val_accuracy: 0.6444\n",
            "Epoch 92/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5022 - accuracy: 0.8479 - val_loss: 1.3557 - val_accuracy: 0.6423\n",
            "Epoch 93/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4921 - accuracy: 0.8513 - val_loss: 1.3847 - val_accuracy: 0.6399\n",
            "Epoch 94/1000\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.4898 - accuracy: 0.8517 - val_loss: 1.3874 - val_accuracy: 0.6418\n",
            "Epoch 95/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.4829 - accuracy: 0.8547 - val_loss: 1.3982 - val_accuracy: 0.6380\n",
            "Epoch 96/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4780 - accuracy: 0.8561 - val_loss: 1.4043 - val_accuracy: 0.6420\n",
            "Epoch 97/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4711 - accuracy: 0.8581 - val_loss: 1.4092 - val_accuracy: 0.6425\n",
            "Epoch 98/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4676 - accuracy: 0.8599 - val_loss: 1.4257 - val_accuracy: 0.6395\n",
            "Epoch 99/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4608 - accuracy: 0.8627 - val_loss: 1.4375 - val_accuracy: 0.6399\n",
            "Epoch 100/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4549 - accuracy: 0.8640 - val_loss: 1.4346 - val_accuracy: 0.6430\n",
            "Epoch 101/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4512 - accuracy: 0.8648 - val_loss: 1.4458 - val_accuracy: 0.6393\n",
            "Epoch 102/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4448 - accuracy: 0.8676 - val_loss: 1.4751 - val_accuracy: 0.6375\n",
            "Epoch 103/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4391 - accuracy: 0.8695 - val_loss: 1.4773 - val_accuracy: 0.6377\n",
            "Epoch 104/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4395 - accuracy: 0.8686 - val_loss: 1.4616 - val_accuracy: 0.6393\n",
            "Epoch 105/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4288 - accuracy: 0.8737 - val_loss: 1.4975 - val_accuracy: 0.6385\n",
            "Epoch 106/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4259 - accuracy: 0.8740 - val_loss: 1.4908 - val_accuracy: 0.6379\n",
            "Epoch 107/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4204 - accuracy: 0.8751 - val_loss: 1.5033 - val_accuracy: 0.6392\n",
            "Epoch 108/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4159 - accuracy: 0.8774 - val_loss: 1.5126 - val_accuracy: 0.6371\n",
            "Epoch 109/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4123 - accuracy: 0.8783 - val_loss: 1.5171 - val_accuracy: 0.6373\n",
            "Epoch 110/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4098 - accuracy: 0.8794 - val_loss: 1.5142 - val_accuracy: 0.6387\n",
            "Epoch 111/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4014 - accuracy: 0.8832 - val_loss: 1.5388 - val_accuracy: 0.6380\n",
            "Epoch 112/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4001 - accuracy: 0.8828 - val_loss: 1.5405 - val_accuracy: 0.6386\n",
            "Epoch 113/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3933 - accuracy: 0.8848 - val_loss: 1.5454 - val_accuracy: 0.6376\n",
            "Epoch 114/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.3890 - accuracy: 0.8868 - val_loss: 1.5621 - val_accuracy: 0.6362\n",
            "Epoch 115/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3869 - accuracy: 0.8873 - val_loss: 1.5771 - val_accuracy: 0.6370\n",
            "Epoch 116/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3803 - accuracy: 0.8893 - val_loss: 1.5822 - val_accuracy: 0.6358\n",
            "Epoch 117/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3769 - accuracy: 0.8906 - val_loss: 1.5982 - val_accuracy: 0.6365\n",
            "Epoch 118/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3735 - accuracy: 0.8912 - val_loss: 1.6087 - val_accuracy: 0.6362\n",
            "Epoch 119/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3686 - accuracy: 0.8931 - val_loss: 1.6152 - val_accuracy: 0.6354\n",
            "Epoch 120/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.3669 - accuracy: 0.8935 - val_loss: 1.6234 - val_accuracy: 0.6371\n",
            "Epoch 121/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3591 - accuracy: 0.8970 - val_loss: 1.6349 - val_accuracy: 0.6346\n",
            "Epoch 122/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.3554 - accuracy: 0.8980 - val_loss: 1.6493 - val_accuracy: 0.6339\n",
            "Epoch 123/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3534 - accuracy: 0.8992 - val_loss: 1.6261 - val_accuracy: 0.6366\n",
            "Epoch 124/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3511 - accuracy: 0.8993 - val_loss: 1.6502 - val_accuracy: 0.6368\n",
            "Epoch 125/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3451 - accuracy: 0.9014 - val_loss: 1.6645 - val_accuracy: 0.6342\n",
            "Epoch 126/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.3430 - accuracy: 0.9022 - val_loss: 1.6671 - val_accuracy: 0.6346\n",
            "Epoch 127/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3372 - accuracy: 0.9043 - val_loss: 1.6889 - val_accuracy: 0.6347\n",
            "Epoch 128/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3397 - accuracy: 0.9032 - val_loss: 1.6793 - val_accuracy: 0.6356\n",
            "Epoch 129/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3263 - accuracy: 0.9089 - val_loss: 1.6929 - val_accuracy: 0.6327\n",
            "Epoch 130/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3302 - accuracy: 0.9064 - val_loss: 1.6989 - val_accuracy: 0.6345\n",
            "Epoch 131/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3262 - accuracy: 0.9075 - val_loss: 1.7167 - val_accuracy: 0.6341\n",
            "Epoch 132/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3205 - accuracy: 0.9101 - val_loss: 1.7442 - val_accuracy: 0.6340\n",
            "Epoch 133/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3209 - accuracy: 0.9093 - val_loss: 1.7264 - val_accuracy: 0.6345\n",
            "Epoch 134/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3150 - accuracy: 0.9118 - val_loss: 1.7384 - val_accuracy: 0.6329\n",
            "Epoch 135/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3105 - accuracy: 0.9134 - val_loss: 1.7455 - val_accuracy: 0.6335\n",
            "Epoch 136/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.3091 - accuracy: 0.9134 - val_loss: 1.7323 - val_accuracy: 0.6335\n",
            "Epoch 137/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3081 - accuracy: 0.9137 - val_loss: 1.7721 - val_accuracy: 0.6313\n",
            "Epoch 138/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3025 - accuracy: 0.9161 - val_loss: 1.7934 - val_accuracy: 0.6314\n",
            "Epoch 139/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3007 - accuracy: 0.9160 - val_loss: 1.7886 - val_accuracy: 0.6345\n",
            "Epoch 140/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2961 - accuracy: 0.9178 - val_loss: 1.7956 - val_accuracy: 0.6339\n",
            "Epoch 141/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2951 - accuracy: 0.9181 - val_loss: 1.8119 - val_accuracy: 0.6331\n",
            "Epoch 142/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2918 - accuracy: 0.9188 - val_loss: 1.8021 - val_accuracy: 0.6331\n",
            "Epoch 143/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2892 - accuracy: 0.9194 - val_loss: 1.8222 - val_accuracy: 0.6321\n",
            "Epoch 144/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2870 - accuracy: 0.9205 - val_loss: 1.8383 - val_accuracy: 0.6321\n",
            "Epoch 145/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2812 - accuracy: 0.9225 - val_loss: 1.8402 - val_accuracy: 0.6322\n",
            "Epoch 146/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2819 - accuracy: 0.9218 - val_loss: 1.8568 - val_accuracy: 0.6317\n",
            "Epoch 147/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2786 - accuracy: 0.9229 - val_loss: 1.8590 - val_accuracy: 0.6293\n",
            "Epoch 148/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2762 - accuracy: 0.9238 - val_loss: 1.8984 - val_accuracy: 0.6296\n",
            "Epoch 149/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2710 - accuracy: 0.9257 - val_loss: 1.8850 - val_accuracy: 0.6314\n",
            "Epoch 150/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2703 - accuracy: 0.9263 - val_loss: 1.8670 - val_accuracy: 0.6347\n",
            "Epoch 151/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2689 - accuracy: 0.9267 - val_loss: 1.8969 - val_accuracy: 0.6290\n",
            "Epoch 152/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2637 - accuracy: 0.9278 - val_loss: 1.8994 - val_accuracy: 0.6320\n",
            "Epoch 153/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2653 - accuracy: 0.9264 - val_loss: 1.9008 - val_accuracy: 0.6306\n",
            "Epoch 154/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2604 - accuracy: 0.9288 - val_loss: 1.8989 - val_accuracy: 0.6323\n",
            "Epoch 155/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2564 - accuracy: 0.9301 - val_loss: 1.9356 - val_accuracy: 0.6315\n",
            "Epoch 156/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2559 - accuracy: 0.9303 - val_loss: 1.9499 - val_accuracy: 0.6320\n",
            "Epoch 157/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2542 - accuracy: 0.9307 - val_loss: 1.9367 - val_accuracy: 0.6320\n",
            "Epoch 158/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2507 - accuracy: 0.9314 - val_loss: 1.9453 - val_accuracy: 0.6298\n",
            "Epoch 159/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2509 - accuracy: 0.9317 - val_loss: 1.9697 - val_accuracy: 0.6315\n",
            "Epoch 160/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2466 - accuracy: 0.9335 - val_loss: 1.9687 - val_accuracy: 0.6326\n",
            "Epoch 161/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2456 - accuracy: 0.9333 - val_loss: 1.9730 - val_accuracy: 0.6303\n",
            "Epoch 162/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2407 - accuracy: 0.9352 - val_loss: 1.9784 - val_accuracy: 0.6313\n",
            "Epoch 163/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2407 - accuracy: 0.9354 - val_loss: 2.0062 - val_accuracy: 0.6306\n",
            "Epoch 164/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2467 - accuracy: 0.9319 - val_loss: 1.9711 - val_accuracy: 0.6307\n",
            "Epoch 165/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2319 - accuracy: 0.9382 - val_loss: 2.0139 - val_accuracy: 0.6306\n",
            "Epoch 166/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2353 - accuracy: 0.9365 - val_loss: 2.0252 - val_accuracy: 0.6276\n",
            "Epoch 167/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2342 - accuracy: 0.9367 - val_loss: 2.0168 - val_accuracy: 0.6294\n",
            "Epoch 168/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2295 - accuracy: 0.9382 - val_loss: 2.0376 - val_accuracy: 0.6302\n",
            "Epoch 169/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2289 - accuracy: 0.9385 - val_loss: 2.0384 - val_accuracy: 0.6284\n",
            "Epoch 170/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2257 - accuracy: 0.9396 - val_loss: 2.0384 - val_accuracy: 0.6314\n",
            "Epoch 171/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2255 - accuracy: 0.9393 - val_loss: 2.0559 - val_accuracy: 0.6305\n",
            "Epoch 172/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2220 - accuracy: 0.9405 - val_loss: 2.0804 - val_accuracy: 0.6302\n",
            "Epoch 173/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2203 - accuracy: 0.9412 - val_loss: 2.0693 - val_accuracy: 0.6288\n",
            "Epoch 174/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2232 - accuracy: 0.9396 - val_loss: 2.0634 - val_accuracy: 0.6278\n",
            "Epoch 175/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2175 - accuracy: 0.9419 - val_loss: 2.0668 - val_accuracy: 0.6293\n",
            "Epoch 176/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2151 - accuracy: 0.9423 - val_loss: 2.0737 - val_accuracy: 0.6308\n",
            "Epoch 177/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2161 - accuracy: 0.9418 - val_loss: 2.0887 - val_accuracy: 0.6310\n",
            "Epoch 178/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2137 - accuracy: 0.9427 - val_loss: 2.0947 - val_accuracy: 0.6315\n",
            "Epoch 179/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2101 - accuracy: 0.9433 - val_loss: 2.1177 - val_accuracy: 0.6302\n",
            "Epoch 180/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2109 - accuracy: 0.9432 - val_loss: 2.1310 - val_accuracy: 0.6299\n",
            "Epoch 181/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2081 - accuracy: 0.9439 - val_loss: 2.1259 - val_accuracy: 0.6322\n",
            "Epoch 182/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2039 - accuracy: 0.9461 - val_loss: 2.1456 - val_accuracy: 0.6311\n",
            "Epoch 183/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2048 - accuracy: 0.9450 - val_loss: 2.1498 - val_accuracy: 0.6289\n",
            "Epoch 184/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2049 - accuracy: 0.9442 - val_loss: 2.1465 - val_accuracy: 0.6284\n",
            "Epoch 185/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1985 - accuracy: 0.9470 - val_loss: 2.1693 - val_accuracy: 0.6280\n",
            "Epoch 186/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2003 - accuracy: 0.9460 - val_loss: 2.1789 - val_accuracy: 0.6304\n",
            "Epoch 187/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1979 - accuracy: 0.9472 - val_loss: 2.1866 - val_accuracy: 0.6307\n",
            "Epoch 188/1000\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.1951 - accuracy: 0.9479 - val_loss: 2.1784 - val_accuracy: 0.6318\n",
            "Epoch 189/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1946 - accuracy: 0.9477 - val_loss: 2.1902 - val_accuracy: 0.6281\n",
            "Epoch 190/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1938 - accuracy: 0.9480 - val_loss: 2.2016 - val_accuracy: 0.6296\n",
            "Epoch 191/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1918 - accuracy: 0.9490 - val_loss: 2.1985 - val_accuracy: 0.6312\n",
            "Epoch 192/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1913 - accuracy: 0.9487 - val_loss: 2.1972 - val_accuracy: 0.6292\n",
            "Epoch 193/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1909 - accuracy: 0.9490 - val_loss: 2.1927 - val_accuracy: 0.6301\n",
            "Epoch 194/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1881 - accuracy: 0.9496 - val_loss: 2.2567 - val_accuracy: 0.6289\n",
            "Epoch 195/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1877 - accuracy: 0.9496 - val_loss: 2.2313 - val_accuracy: 0.6319\n",
            "Epoch 196/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1850 - accuracy: 0.9507 - val_loss: 2.2297 - val_accuracy: 0.6296\n",
            "Epoch 197/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1858 - accuracy: 0.9501 - val_loss: 2.2323 - val_accuracy: 0.6317\n",
            "Epoch 198/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1853 - accuracy: 0.9501 - val_loss: 2.2179 - val_accuracy: 0.6316\n",
            "Epoch 199/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1800 - accuracy: 0.9521 - val_loss: 2.2585 - val_accuracy: 0.6284\n",
            "Epoch 200/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1800 - accuracy: 0.9520 - val_loss: 2.2617 - val_accuracy: 0.6310\n",
            "Epoch 201/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1772 - accuracy: 0.9526 - val_loss: 2.2570 - val_accuracy: 0.6292\n",
            "Epoch 202/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1779 - accuracy: 0.9523 - val_loss: 2.2843 - val_accuracy: 0.6285\n",
            "Epoch 203/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1784 - accuracy: 0.9522 - val_loss: 2.2971 - val_accuracy: 0.6273\n",
            "Epoch 204/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1797 - accuracy: 0.9513 - val_loss: 2.2809 - val_accuracy: 0.6297\n",
            "Epoch 205/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1721 - accuracy: 0.9538 - val_loss: 2.3246 - val_accuracy: 0.6302\n",
            "Epoch 206/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1749 - accuracy: 0.9530 - val_loss: 2.3034 - val_accuracy: 0.6306\n",
            "Epoch 207/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1705 - accuracy: 0.9543 - val_loss: 2.3316 - val_accuracy: 0.6299\n",
            "Epoch 208/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1732 - accuracy: 0.9532 - val_loss: 2.2860 - val_accuracy: 0.6302\n",
            "Epoch 209/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1711 - accuracy: 0.9542 - val_loss: 2.3026 - val_accuracy: 0.6298\n",
            "Epoch 210/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1723 - accuracy: 0.9534 - val_loss: 2.3294 - val_accuracy: 0.6309\n",
            "Epoch 211/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1669 - accuracy: 0.9554 - val_loss: 2.3061 - val_accuracy: 0.6318\n",
            "Epoch 212/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1666 - accuracy: 0.9551 - val_loss: 2.3550 - val_accuracy: 0.6295\n",
            "Epoch 213/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1668 - accuracy: 0.9548 - val_loss: 2.3624 - val_accuracy: 0.6282\n",
            "Epoch 214/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1663 - accuracy: 0.9548 - val_loss: 2.3579 - val_accuracy: 0.6324\n",
            "Epoch 215/1000\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1667 - accuracy: 0.9546 - val_loss: 2.3659 - val_accuracy: 0.6300\n",
            "Epoch 216/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1648 - accuracy: 0.9551 - val_loss: 2.3500 - val_accuracy: 0.6297\n",
            "Epoch 217/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1629 - accuracy: 0.9560 - val_loss: 2.3789 - val_accuracy: 0.6309\n",
            "Epoch 218/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1630 - accuracy: 0.9560 - val_loss: 2.3640 - val_accuracy: 0.6300\n",
            "Epoch 219/1000\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.1605 - accuracy: 0.9566 - val_loss: 2.3794 - val_accuracy: 0.6312\n",
            "Epoch 220/1000\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.1601 - accuracy: 0.9569 - val_loss: 2.3729 - val_accuracy: 0.6295\n",
            "Epoch 221/1000\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.1667 - accuracy: 0.9539 - val_loss: 2.3910 - val_accuracy: 0.6314\n",
            "Epoch 222/1000\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.1528 - accuracy: 0.9588 - val_loss: 2.4186 - val_accuracy: 0.6283\n",
            "Epoch 223/1000\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 0.1562 - accuracy: 0.9574 - val_loss: 2.4129 - val_accuracy: 0.6313\n",
            "Epoch 224/1000\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.1586 - accuracy: 0.9570 - val_loss: 2.4198 - val_accuracy: 0.6316\n",
            "Epoch 225/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1581 - accuracy: 0.9566 - val_loss: 2.4248 - val_accuracy: 0.6313\n",
            "Epoch 226/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1581 - accuracy: 0.9569 - val_loss: 2.4222 - val_accuracy: 0.6300\n",
            "Epoch 227/1000\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1538 - accuracy: 0.9580 - val_loss: 2.4411 - val_accuracy: 0.6313\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mWARNING \u001b[0m Found untraced functions such as lstm_cell_layer_call_fn,                           \n",
              "         lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn,      \n",
              "         lstm_cell_1_layer_call_and_return_conditional_losses while saving \u001b[1m(\u001b[0mshowing \u001b[1;36m4\u001b[0m of \u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m. \n",
              "         These functions will not be directly callable after loading.                        \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Found untraced functions such as lstm_cell_layer_call_fn,                           \n",
              "         lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn,      \n",
              "         lstm_cell_1_layer_call_and_return_conditional_losses while saving <span style=\"font-weight: bold\">(</span>showing <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>. \n",
              "         These functions will not be directly callable after loading.                        \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mWARNING \u001b[0m \u001b[1m<\u001b[0m\u001b[1;95mkeras.layers.recurrent.LSTMCell\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7f5c1e0f6590\u001b[0m\u001b[1m>\u001b[0m has the same name        \n",
              "         \u001b[32m'LSTMCell'\u001b[0m as a built-in Keras object. Consider renaming \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                    \n",
              "         \u001b[32m'keras.layers.recurrent.LSTMCell'\u001b[0m\u001b[1m>\u001b[0m to avoid naming conflicts when loading with      \n",
              "         `tf.keras.models.load_model`. If renaming is not possible, pass the object in the   \n",
              "         `custom_objects` parameter of the load function.                                    \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">keras.layers.recurrent.LSTMCell</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f5c1e0f6590</span><span style=\"font-weight: bold\">&gt;</span> has the same name        \n",
              "         <span style=\"color: #008000; text-decoration-color: #008000\">'LSTMCell'</span> as a built-in Keras object. Consider renaming <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span>                    \n",
              "         <span style=\"color: #008000; text-decoration-color: #008000\">'keras.layers.recurrent.LSTMCell'</span><span style=\"font-weight: bold\">&gt;</span> to avoid naming conflicts when loading with      \n",
              "         `tf.keras.models.load_model`. If renaming is not possible, pass the object in the   \n",
              "         `custom_objects` parameter of the load function.                                    \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mWARNING \u001b[0m \u001b[1m<\u001b[0m\u001b[1;95mkeras.layers.recurrent.LSTMCell\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x7f5c10541290\u001b[0m\u001b[1m>\u001b[0m has the same name        \n",
              "         \u001b[32m'LSTMCell'\u001b[0m as a built-in Keras object. Consider renaming \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                    \n",
              "         \u001b[32m'keras.layers.recurrent.LSTMCell'\u001b[0m\u001b[1m>\u001b[0m to avoid naming conflicts when loading with      \n",
              "         `tf.keras.models.load_model`. If renaming is not possible, pass the object in the   \n",
              "         `custom_objects` parameter of the load function.                                    \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">keras.layers.recurrent.LSTMCell</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f5c10541290</span><span style=\"font-weight: bold\">&gt;</span> has the same name        \n",
              "         <span style=\"color: #008000; text-decoration-color: #008000\">'LSTMCell'</span> as a built-in Keras object. Consider renaming <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span>                    \n",
              "         <span style=\"color: #008000; text-decoration-color: #008000\">'keras.layers.recurrent.LSTMCell'</span><span style=\"font-weight: bold\">&gt;</span> to avoid naming conflicts when loading with      \n",
              "         `tf.keras.models.load_model`. If renaming is not possible, pass the object in the   \n",
              "         `custom_objects` parameter of the load function.                                    \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "# Save model\n",
        "model.save(\"s2s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrtVFj9ISIJ1"
      },
      "source": [
        "## Run inference (sampling)\n",
        "\n",
        "1. encode input and retrieve initial decoder state\n",
        "2. run one step of decoder with this initial state\n",
        "and a \"start of sequence\" token as target.\n",
        "Output will be the next target token.\n",
        "3. Repeat with the current target token and current states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flc9FRs8SIJ1"
      },
      "outputs": [],
      "source": [
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"s2s\")\n",
        "\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGL0NRCuSIJ2"
      },
      "source": [
        "You can now generate decoded sentences as such:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kVFtz4VSIJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f3057b4-c7b5-4374-c949-60efa9d24483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: εγγενομεναπαδημησμεννωτες αλλατηε κλησει\n",
            "Decoded sentence: και τους κακους δραν πανταχου κακως αει\n",
            "\n",
            "-\n",
            "Input sentence: του β ου του καλεαυτους πολλαγινεσθαι συγχωρ ον\n",
            "Decoded sentence: τουτο το σχημα το υπερηφανον και ποληται\n",
            "\n",
            "-\n",
            "Input sentence: τες εμπυριζου σιμαμπελωνα αλλακαι οδξα\n",
            "Decoded sentence: και τους κακους δραν πανταχου κακως αει\n",
            "\n",
            "-\n",
            "Input sentence: της εδιας πλσον εξιας πολλους εις την των αλ\n",
            "Decoded sentence: τουτο το σχημα το υπερηφανον και ποπης\n",
            "\n",
            "-\n",
            "Input sentence: λοτρλων επιθυμιαν προκαλουμενος εμπυρι\n",
            "Decoded sentence: πολλοις διαλανθανει και εις γνωσιν τοις\n",
            "\n",
            "-\n",
            "Input sentence: λει τον αμπελωνα συναπτειγαρ τοκαι καρπα\n",
            "Decoded sentence: τουτο το σχημα το υπερηφανον και πεποιη\n",
            "\n",
            "-\n",
            "Input sentence: γη του πτωχουεντοις οικοιςχμων ωστεκακα\n",
            "Decoded sentence: πολλοις διαλανθανει και εις τον του και τανταγγαντεν ταιαι\n",
            "\n",
            "-\n",
            "Input sentence: ικον κτησιν αποαρπαγης καιβωας συγεγοντεσ\n",
            "Decoded sentence: τουτο το σχημα το υπερηφανον και πεποιη\n",
            "\n",
            "-\n",
            "Input sentence: αιτιαν του εμπρησμου τω αμπελωνιπαρεχησι\n",
            "Decoded sentence: τουτο το σχημα το υπερηφανον και πεποιη\n",
            "\n",
            "-\n",
            "Input sentence: εκ του πον ηρουχυποδειχματος του κατατους προ\n",
            "Decoded sentence: και τους κακους δραν πανταχου κακως αει\n",
            "\n",
            "-\n",
            "Input sentence: ετωτας και του λαουπαντος εις την καταλλης\n",
            "Decoded sentence: και τους κακους δραν πανταχου κακως αει\n",
            "\n",
            "-\n",
            "Input sentence: λων πλονξιαν παιδοτριβομενου πρεσυν\n",
            "Decoded sentence: προς του σταζοντες αυτους καιδες μεν εορ\n",
            "\n",
            "-\n",
            "Input sentence: προιον καραρχοντες οιμη διατης γγιαι νουσις\n",
            "Decoded sentence: ουκ εστιν ουδεν των εν ανθρωποις ισον\n",
            "\n",
            "-\n",
            "Input sentence: διδασκαλιας και των κατα τον ιιουμει ον αγαλλων\n",
            "Decoded sentence: τουτο το σχημα το υπερηφανον και πεποιη\n",
            "\n",
            "-\n",
            "Input sentence: πο δει γματων τον αμπεμων αγεωργουντες ταυτα\n",
            "Decoded sentence: πολλοις διαλανθανει και εις γνωσιν τοις παρειν \n",
            "\n",
            "-\n",
            "Input sentence: εγλληθησομεθα ευζοιωσδεκαι ακουσομεθα το\n",
            "Decoded sentence: και τους κακους δραν πανταχου κακως αει\n",
            "\n",
            "-\n",
            "Input sentence: καικαρπεαγη του πτωχουεν τοις οικοις χμων\n",
            "Decoded sentence: και τους κακους δραν πανταχου κακως αει\n",
            "\n",
            "-\n",
            "Input sentence: δαντα ειςλογοντης αναπαυως των πενητω\n",
            "Decoded sentence: πολλοις διαλανθανει και εις γνωσιν τοις\n",
            "\n",
            "-\n",
            "Input sentence: διδομεναδεντοις ο ικοις εχωμεν αποστερουντες\n",
            "Decoded sentence: τουτο το σχημα το υπερηφανον και πεποιη\n",
            "\n",
            "-\n",
            "Input sentence: τους ενδεεις ωτιαμεις απικει τε τοη λαου\n",
            "Decoded sentence: τουτο το σχημα το υπερηφανον και πεποιη\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for seq_index in range(20):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"Input sentence:\", input_texts[seq_index])\n",
        "    print(\"Decoded sentence:\", decoded_sentence)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lstm_seq2seq",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1178144ea0454fd2b55a83ea185a7f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd5443463eb0420e92ba13900eb70baa",
              "IPY_MODEL_ee7917315b9a4387ae16e69d79aa677f",
              "IPY_MODEL_2dcc5bd8c93949e0adf684dc8ae543e3"
            ],
            "layout": "IPY_MODEL_f273f507bec74316b72246a77b21c74c"
          }
        },
        "fd5443463eb0420e92ba13900eb70baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a3d73af91424aa49bb6378b6d30de7f",
            "placeholder": "​",
            "style": "IPY_MODEL_880917de59614bbbb5251c6151397a20",
            "value": "test.csv: 100%"
          }
        },
        "ee7917315b9a4387ae16e69d79aa677f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f0f48edce243379df5a1308612d1a0",
            "max": 45547,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be4bd1fd2c0e46fd8119273e2a3d965e",
            "value": 45547
          }
        },
        "2dcc5bd8c93949e0adf684dc8ae543e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_603eaeb4996e4a5e9d2b1584a8539da3",
            "placeholder": "​",
            "style": "IPY_MODEL_986e33e5a31e46c28ce149efdd0ea31a",
            "value": " 45.5k/45.5k [00:00&lt;00:00, 604kB/s]"
          }
        },
        "f273f507bec74316b72246a77b21c74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a3d73af91424aa49bb6378b6d30de7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "880917de59614bbbb5251c6151397a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5f0f48edce243379df5a1308612d1a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be4bd1fd2c0e46fd8119273e2a3d965e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "603eaeb4996e4a5e9d2b1584a8539da3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "986e33e5a31e46c28ce149efdd0ea31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1986e8da3ea486797a0b18ac364c5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_962aafdf60d7424c824fa03219d97fd9",
              "IPY_MODEL_5ce2a00a18bf43349aa327924bd85208",
              "IPY_MODEL_5f5227031fdc4ed9b929913e9ecb39f3"
            ],
            "layout": "IPY_MODEL_f42168c9d4534e73a681373b330dea85"
          }
        },
        "962aafdf60d7424c824fa03219d97fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7cbfbaac24d477ab16a0e3792deb7f7",
            "placeholder": "​",
            "style": "IPY_MODEL_b639396a16b140399931daf33570b139",
            "value": "train.csv: 100%"
          }
        },
        "5ce2a00a18bf43349aa327924bd85208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c4790797b264b71a2e483c968c80126",
            "max": 395041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b487fa018c74669aeaeaae4b65cb79f",
            "value": 395041
          }
        },
        "5f5227031fdc4ed9b929913e9ecb39f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a64f38a1cd524297826e514effc8e21e",
            "placeholder": "​",
            "style": "IPY_MODEL_fde364e916f64dccb74f164063ca4bfc",
            "value": " 395k/395k [00:00&lt;00:00, 1.31MB/s]"
          }
        },
        "f42168c9d4534e73a681373b330dea85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7cbfbaac24d477ab16a0e3792deb7f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b639396a16b140399931daf33570b139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c4790797b264b71a2e483c968c80126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b487fa018c74669aeaeaae4b65cb79f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a64f38a1cd524297826e514effc8e21e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fde364e916f64dccb74f164063ca4bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}